{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ephra\\Documents\\GitHub\\DSIW-Project\\train\n",
      "C:\\Users\\ephra\\Documents\\GitHub\\DSIW-Project\\test\n"
     ]
    }
   ],
   "source": [
    "train_wd = os.path.join(os.getcwd(),'train')\n",
    "test_wd = os.path.join(os.getcwd(), 'test')\n",
    "print (train_wd)\n",
    "print (test_wd)\n",
    "print (train_wd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "trainfiles = [f for f in listdir(train_wd) if isfile(join(train_wd, f))]\n",
    "testfiles = [f for f in listdir(test_wd) if isfile(join(test_wd,f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235773\n",
      "7166\n"
     ]
    }
   ],
   "source": [
    "print(len(trainfiles)) # 235813\n",
    "print(len(testfiles)) # 7166"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train.csv\n",
    "import csv\n",
    "all_train = {}\n",
    "iter = 0\n",
    "\n",
    "with open(os.path.join(os.getcwd(), 'train.csv')) as train_csvfile:\n",
    "    reader = csv.DictReader(train_csvfile)\n",
    "    # create lookup dictionary for images that have been successfully downloaded\n",
    "    for row in reader:\n",
    "        all_train[row['id']] = row['landmark_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "# load training data\n",
    "\n",
    "train_labels = []\n",
    "train_vectors = []\n",
    "bad_train_data = []\n",
    "\n",
    "itr = 0\n",
    "img_size = (32,32)\n",
    "for filename in trainfiles:\n",
    "    img = cv2.imread(os.path.join(train_wd,filename),0) # 0 second input for greyscale.\n",
    "    #img=cv2.resize(img, img_size)\n",
    "    #edges = cv2.Canny(img,100,200)\n",
    "    #sift=cv2.xfeatures2d.SIFT_create()\n",
    "    #kp, des=sift.detectAndCompute(img,None)\n",
    "    # flatten image\n",
    "    try:\n",
    "        img = cv2.resize(img, img_size).flatten()\n",
    "        #des=des.flatten()\n",
    "    except Exception: \n",
    "        bad_train_data.append(filename)\n",
    "        continue\n",
    "\n",
    "    # append to vector of lists\n",
    "    train_vectors.append(img)\n",
    "\n",
    "    # find targets\n",
    "    fn = filename.replace('.jpg','')\n",
    "    train_labels.append(all_train[fn])\n",
    "    itr = itr + 1\n",
    "    if itr % 10000 == 0:\n",
    "        print(itr)\n",
    "#fit KNN\n",
    "\n",
    "    \n",
    "#run on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(train_vectors)\n",
    "y=np.array(train_labels)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23578\n"
     ]
    }
   ],
   "source": [
    "print (len (X_test))\n",
    "y_train=y_train.astype(int)\n",
    "y_test=y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.astype(np.float32)\n",
    "X_test=X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local current time : Sun May  6 20:29:22 2018\n",
      "Begin\n"
     ]
    }
   ],
   "source": [
    "svm_params = dict( kernel_type = cv2.ml.SVM_LINEAR,\n",
    "                    svm_type = cv2.ml.SVM_C_SVC,\n",
    "                    C=2.67, gamma=5.383 )\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)\n",
    "print(\"Begin\")\n",
    "svm = cv2.ml.SVM_create()\n",
    "svm.train(X_train,cv2.ml.ROW_SAMPLE, y_train)\n",
    "print (\"Training complete\")\n",
    "svm.save('svm_data.dat')\n",
    "print (\"Local current time :\", localtime)\n",
    "pred = svm.predict_all(X_test)\n",
    "print (\"Prediction complete\")\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=f1_score(y_test, pred, average='macro')\n",
    "print (\"score is \"+ str(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(random_state=0, verbose=True)\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)\n",
    "print(\"Begin\")\n",
    "clf.fit(X_train, y_train)\n",
    "print (\"Training complete\")\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)\n",
    "pred=clf.predict(X_test)\n",
    "print (\"Prediction complete\")\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)\n",
    "print(\"Begin\")\n",
    "clf.fit(X_train, y_train)\n",
    "print (\"Training complete\")\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)\n",
    "pred=clf.predict(X_test)\n",
    "print (\"Prediction complete\")\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)\n",
    "print(\"Begin\")\n",
    "clf.fit(X_train, y_train)\n",
    "print (\"Training complete\")\n",
    "pred=clf.predict(X_test)\n",
    "print (\"Prediction complete\")\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)\n",
    "print(\"Begin\")\n",
    "clf.fit(X_train, y_train)\n",
    "print (\"Training complete\")\n",
    "pred=clf.predict(X_test)\n",
    "print (\"Prediction complete\")\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model and run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "knn = cv2.ml.KNearest_create()\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)\n",
    "print(\"Begin\")\n",
    "knn.train(X_train,cv2.ml.ROW_SAMPLE, y_train)\n",
    "print (\"Training complete\")\n",
    "ret,result,neighbours,dist = knn.findNearest(X_test,k=3)\n",
    "print (\"Prediction complete\")\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=f1_score(y_test, result, average='macro')\n",
    "print (\"score is \"+ str(score))\n",
    "matches = result==y_test\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = correct/(len(result))\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import f1_score\n",
    "#v=int(math.sqrt(len(X_train)))\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print (\"Local current time :\", localtime)\n",
    "print(\"Begin\")\n",
    "all_f1_scores=[]\n",
    "all_k=range(3,5,2)\n",
    "for k in all_k:\n",
    "    neigh = KNN(n_neighbors=k, n_jobs=-1)# multi core support\n",
    "    print (\"k: \"+str(k) +\" starting\")\n",
    "    neigh.fit(X_train, y_train)\n",
    "    print (\"Fitting complete\")\n",
    "    y_pred=neigh.predict(X_test)\n",
    "    print (\"Prediction complete\")\n",
    "    localtime = time.asctime( time.localtime(time.time()) )\n",
    "    print (\"Local current time :\", localtime)\n",
    "    score=f1_score(y_test, y_pred, average='macro')\n",
    "    all_f1_scores.append(score)\n",
    "    print (\"k: \"+str(k) + \"  f1_score: \"+str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
